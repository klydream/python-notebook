I didn't meet any trouble on installing this program 
Refering to https://www.elastic.co/guide/en/logstash/6.2/advanced-pipeline.html
(1)Install firebeat and config in filebeat.yml
filebeat.prospectors:
- type: log
  paths:
    - /path/to/file/logstash-tutorial.log 
output.logstash:
  hosts: ["localhost:5044"]
  
(2)Start ./filebeat -e -c filebeat.yml -d "publish"

(3)Install logstash and config in 
input {
    beats {
        port => "5044"
    }
}
# The filter part of this file is commented out to indicate that it is
# optional.
# filter {
#
# }
output {
    stdout { codec => json }
}
output {
  kafka {
    codec => json
    bootstrap_servers => "localhost:9092"
    topic_id => "test"
  }
}
To connect with Kafka, I was going to use Avro, but I found the codec mode of logstash-codec-avro is not same with kafka
even if I false Base64. So I only can use json.

If I want to use avro again, I should continue to modify file of logstash-codec-avro.

(4)bin/logstash -f first-pipeline.conf --config.reload.automatic

(5)Install plugin Avro by command "bin/logstash-plugin install logstash-codec-avro" and config by
input {
  kafka {
    codec => avro {
        schema_uri => "/tmp/schema.avsc"
    }
  }
}
or install your own code by 
a. Edit Logstash Gemfile and add the local plugin path, for example:
gem "logstash-codec-avro", :path => "/your/local/logstash-codec-avro"
b. bin/logstash-plugin install --no-verify



